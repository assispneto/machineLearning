{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3f0a035-369f-4051-bba8-beb9a214626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # @autor: assispaivaneto\n",
    "    # @data: 20/11/2021\n",
    "    # @objetivo: pre-processmento de um dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d83112-f805-43ce-bfed-853d179eb005",
   "metadata": {},
   "source": [
    "Existem diversas maneiras de um dado ser criado ou alterado, com isso o modo como conhecemos\n",
    "algum determinado tipo de dado oscila de forma incomum, principalmente quando trabalhamos com\n",
    "dados textuais, já que a internet através das redes sociais, entrega diversas possibilidades\n",
    "para as pessoas escrevem conforme sua vontade.\n",
    "\n",
    "Conforme a situação apresentada, sempre temos que nos atentar quando surgir a necessidade de ser \n",
    "feito um processamento de dados, por conta que, na sua forma \"natural\" podem atrapalhar ou atrasar \n",
    "o processo que vai ser realziado.\n",
    "\n",
    "É por conta disso, que surge a necessidade do pré-processamento de dados. E desse modo, quando estamos \n",
    "trabalhando com textos, o pré-processamento acontece nas seguintes etapas:\n",
    "    1 - tornar todas as palaras minúsculas;\n",
    "    2 - excluir as contrações existentes;\n",
    "    3 - remover as pontuações, números e espaços em branco;\n",
    "    4 - tokenizar: processo onde o texto é dividido em partes menores;\n",
    "    5 - lematizar: processo onde consideramos apenas o lema das palavras.\n",
    "    \n",
    "Através desse processo, são eliminados alguns itens que não tem relevância para o processamento\n",
    "final, fazendo com que, essa operação ocorra de maneira mais objetiva e consequentemente mais rápida,\n",
    "clara e obtenha um resultado mais real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65316c4-b1cd-493f-be60-9e04b30823d9",
   "metadata": {},
   "source": [
    " <font size=\"3\"> Importação de bibliotecas e métodos que vão ser utilizados </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e71920-c9ea-42fb-b70d-b28c7f2b637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7b335-51c9-46d8-b4fa-8090ac32ba20",
   "metadata": {},
   "source": [
    " <font size=\"3\"> Carregando a base de dados </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201de801-b9e1-49a9-995c-3c9958f308ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/assis/Documentos/Programação/Python/Projeto final/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f4663-77f8-4c54-82f7-a8a7a3a9289f",
   "metadata": {},
   "source": [
    " <font size=\"3\"> Realocando os dados do dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe89902b-98da-495b-b6b5-d2d2a424aedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_mask = (data[data.columns[2:]] > 0).any(axis=1)\n",
    "data = {\"text\": data[\"comment_text\"], \"toxic\": np.zeros(data.shape[0], dtype=np.int64)}\n",
    "data[\"toxic\"][toxic_mask] = 1\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54675c1-16c7-479f-bcad-7f13a6725844",
   "metadata": {},
   "source": [
    " <font size=\"3\"> Funções para o pré-processamento dos dados </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92774f6-b279-47fb-8b55-46971e13b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def decontracted(phrase):\n",
    "    '''\n",
    "    É comum encontrarmos contrações nas palavras, principalmente quando\n",
    "    estamos trabalhando com textos em inglês (o que acontece com grande\n",
    "    frequência devido a influência e alcance desse idioma).\n",
    "    Desse modo, decontracted() é uma função que \"elimina\" as contrações \n",
    "    existentes.\n",
    "    '''\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def lemmatizeText(text):\n",
    "    '''\n",
    "    A lematização é um processo que reduz a palavra a sua forma base.\n",
    "    De modo que, todas as palavras que possuem a mesma base, sejam \n",
    "    agrupadas. \n",
    "    Como exemplo temos as palvras \"brincar\", \"brincou\",\n",
    "    \"brincava\", todas formas da palavra \"brinca\", dessa forma, a pala-\n",
    "    vra \"brinca\" é o lema de todas as anteriores.\n",
    "    Com isso, a função lemmatizeText(), tem como objetivo aplicar o \n",
    "    processo de lematização que foi mencionado.\n",
    "    '''\n",
    "    doc = nlp(text)\n",
    "    lemmed = [token.lemma_ if token.lemma_ != '-PRON-' else token.text for token in doc]\n",
    "    return ' '.join(lemmed)\n",
    "\n",
    "def preProcessamento(x):\n",
    "    '''\n",
    "    A função preProcessamento() realiza de forma geral o pré-processa-\n",
    "    mento dos dados. Para que isso seja possível, ela faz uso de outras\n",
    "    funções já definidas e de alguns métodos.\n",
    "    '''\n",
    "    x = x.lower()\n",
    "    x = decontracted(str(x))\n",
    "    x = re.sub(r'[^\\w\\s]', ' ', x)\n",
    "    x = re.sub(r'[0-9]+', '', x)\n",
    "    x = nltk.word_tokenize(x)\n",
    "    x = [word for word in x if not word in stopwords.words()]\n",
    "    x = lemmatizeText(' '.join(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64558638-6717-438a-a591-30427b8a36ea",
   "metadata": {},
   "source": [
    " <font size=\"3\"> Realizando o pré-procesamento dos dados </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be762b69-4833-4cef-8020-1edb01a9b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571/159571\r"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "for i, text in enumerate(data['text']):\n",
    "    text = preProcessamento(text)\n",
    "    texts.append(text)\n",
    "    print(f'{i+1}/{data.shape[0]}', end='\\r')\n",
    "    \n",
    "newData = {'text': texts, 'toxic': data['toxic'].tolist()}\n",
    "newData = pd.DataFrame(newData)\n",
    "newData.to_json('PreProcessData.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
